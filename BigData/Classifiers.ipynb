{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **By Kyle Weldon**\n",
    "This file is created and maintained by Kyle Weldon. It was created on 07/30/2024."
   ],
   "id": "47f7184e141ba8f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **New Approach**\n",
    "Below is the imports that will be used for this project."
   ],
   "id": "872613c02125b355"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T22:31:58.354055Z",
     "start_time": "2024-07-30T22:31:48.111619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import simple_colors\n",
    "\n",
    "print(simple_colors.red('VERSIONS USESD:', ['bold', 'underlined', 'italic']))\n",
    "\n",
    "print('NumPy version:', np.__version__)\n",
    "print('Pandas version:', pd.__version__)\n",
    "print('Scikit-learn version:', sklearn.__version__)"
   ],
   "id": "d9ba74c215e9a501",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;4;3;31mVERSIONS USESD:\u001B[0m\n",
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.2.2\n",
      "Scikit-learn version: 1.5.1\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Preparing the data**\n",
    "The data for these models will be prepared in a simalar but different way than the NN model. The people will be put in three groups but instead of having that be but to catagorical it will be left as either a 0, 1, or 2. The data will still have a 4-3-4 catagory split. Below is the code for this."
   ],
   "id": "bb304aaac3a950bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T20:27:38.967181Z",
     "start_time": "2024-07-30T20:27:38.948809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('Data/FilteredData.csv')\n",
    "# Column tites for all the output data\n",
    "output_columns = ['Scenario 1 ',\n",
    "                  'Unnamed: 40',\n",
    "                  'Scenario 2 ',\n",
    "                  'Unnamed: 42',\n",
    "                  'Scenario 3 ',\n",
    "                  'Unnamed: 44',\n",
    "                  'Scenario 4',\n",
    "                  'Unnamed: 46',\n",
    "                  'Scenario 5 ',\n",
    "                  'Unnamed: 48']\n",
    "\n",
    "def classify(column):\n",
    "    return np.array([0 if x <= 3 else 1 if x <= 6 else 2 for x in column])\n",
    "\n",
    "columns = df[output_columns].to_numpy().T # The 'T' is to transpose the array\n",
    "\n",
    "S1P1, S1P2, S2P1, S2P2, S3P1, S3P2, S4P1, S4P2, S5P1, S5P2 = [classify(col) for col in columns]\n",
    "all_situations = [S1P1, S1P2, S2P1, S2P2, S3P1, S3P2, S4P1, S4P2, S5P1, S5P2]\n",
    "\n",
    "for situation in all_situations:\n",
    "    print(situation.shape)"
   ],
   "id": "81d43d651fe0e62c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(881,)\n",
      "(881,)\n",
      "(881,)\n",
      "(881,)\n",
      "(881,)\n",
      "(881,)\n",
      "(881,)\n",
      "(881,)\n",
      "(881,)\n",
      "(881,)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Prepare input data:**\n",
    "Now that the output data is fully prepared and ready for training it is time to prepare the coresponding input data. Simalar to the multiple outputs there our also miltiple inputs. Below is the code to complete this."
   ],
   "id": "ab461a742869d716"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T20:39:27.360016Z",
     "start_time": "2024-07-30T20:39:27.354406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_columns1 = ['MAx1', 'Max2', 'Max3']\n",
    "input_columns2 = ['Q105_1','Q105_2','Q105_3','Q105_4','Q105_5','Q105_6','Q105_7','Q105_8','Q105_9','Q105_10','Q105_11','Q105_12','Q105_13','Q105_14','Q105_15','Q105_16','Q105_17','Q105_18','Q105_19','Q105_20','Q105_21','Q105_22','Q105_23','Q105_24','Q105_25','Q105_26','Q105_27','Q105_28','Q105_29','Q105_30','Q105_31','Q105_32','Q105_33','Q105_34']\n",
    "\n",
    "input_df1 = df[input_columns1]\n",
    "input1_X_values = input_df1.to_numpy()\n",
    "input_df2 = df[input_columns2]\n",
    "input2_X_values = input_df2.to_numpy()\n",
    "x = input2_X_values"
   ],
   "id": "403b5c72795afc43",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Training the model:**",
   "id": "19c503e0e3c667ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T13:23:19.514378Z",
     "start_time": "2024-07-31T13:23:19.493402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "    \n",
    "    # rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "    # gb_model = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, max_depth=3, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "    # dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    # \n",
    "    # rf_model.fit(x_train, y_train)\n",
    "    # gb_model.fit(x_train, y_train)\n",
    "    # dt_model.fit(x_train, y_train)\n",
    "    # \n",
    "    # rf_train_accuracy = rf_model.score(x_train, y_train) * 100\n",
    "    # gb_train_accuracy = gb_model.score(x_train, y_train) * 100\n",
    "    # dt_train_accuracy = dt_model.score(x_train, y_train) * 100\n",
    "    # \n",
    "    # print(f\"Random Forest Training Accuracy: {rf_train_accuracy:.2f}%\")\n",
    "    # print(f\"Gradient Boosting Training Accuracy: {gb_train_accuracy:.2f}%\")\n",
    "    # print(f\"Decision Tree Training Accuracy: {dt_train_accuracy:.2f}%\")\n",
    "    # \n",
    "    # rf_pred = rf_model.predict(x_test)\n",
    "    # gb_pred = gb_model.predict(x_test)\n",
    "    # dt_pred = dt_model.predict(x_test)\n",
    "    # \n",
    "    # rf_acc = accuracy_score(y_test, rf_pred)\n",
    "    # gb_acc = accuracy_score(y_test, gb_pred)\n",
    "    # dt_acc = accuracy_score(y_test, dt_pred)\n",
    "    # print(f'RF = {rf_acc*100:.2f}% | GB = {gb_acc*100:.2f}% | DT = {dt_acc*100:.2f}%')\n",
    "    \n",
    "input = Input(shape=(input2_X_values.shape[1],))\n",
    "\n",
    "hidden1 = Dense(256, activation='relu')(input)\n",
    "hidden2 = Dense(128, activation='relu')(hidden1)\n",
    "hidden3 = Dense(64, activation='relu')(hidden2)\n",
    "hidden4 = Dense(32, activation='relu')(hidden3)\n",
    "hidden5 = Dense(16, activation='relu')(hidden4)\n",
    "\n",
    "def create_output_layer(name, input_layer):\n",
    "    return Dense(3, activation='softmax', name=name)(input_layer)\n",
    "\n",
    "def itterate_situations_and_parts(num_itts=10):\n",
    "    scenerio = 1\n",
    "    sittos = []\n",
    "    for i in range(num_itts):\n",
    "        part = 1 if i % 2 == 0 else 2\n",
    "        sittos.append(f\"S{scenerio}P{part}\")\n",
    "        if part == 2: scenerio += 1\n",
    "    return sittos\n",
    "\n",
    "outputs = [create_output_layer(name, hidden5) for name in itterate_situations_and_parts()]\n",
    "\n",
    "model = Model(inputs=input, outputs=outputs, name='CustomizedDeepNeuralNetwork')\n",
    "\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=metrics)\n",
    "\n",
    "model.fit(input2_X_values, all_situations, epochs=10,\n",
    "                   batch_size=128,\n",
    "                   verbose=1)\n",
    "\n",
    "\n",
    "    "
   ],
   "id": "c425b057417e4798",
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 34 (783754636.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[5], line 35\u001B[1;36m\u001B[0m\n\u001B[1;33m    return Dense(3, activation='softmax', name=name)(input_layer)\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m expected an indented block after function definition on line 34\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T00:36:15.534372Z",
     "start_time": "2024-07-31T00:36:15.525788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    temp = []\n",
    "    # temp.append(rf_pred[i])\n",
    "    # temp.append(gb_pred[i])\n",
    "    #temp.append(dt_pred[i])\n",
    "    temp.append(nn_pred[i].argmax())\n",
    "    avg = int(sum(temp) / len(temp))\n",
    "    if avg == y_test[i]:\n",
    "        correct += 1\n",
    "    print(f'{avg} -> {y_test[i]}')\n",
    "\n",
    "acc = correct / len(y_test) * 100\n",
    "print(f'Accuracy: {acc:.2f}%')\n"
   ],
   "id": "7e07272f08019ade",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 0\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 1\n",
      "2 -> 0\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 1\n",
      "2 -> 1\n",
      "2 -> 1\n",
      "2 -> 1\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 1\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "2 -> 2\n",
      "2 -> 0\n",
      "Accuracy: 78.53%\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "782ea6d07cb423a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
